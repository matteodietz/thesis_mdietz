\chapter{Introduction}
\label{ch:introduction}

For decades, medical ultrasound has been a cornerstone of diagnostics imaging with broad clinical and preclinical applications, valued for its real-time capabilities, non-ionizing nature and relatively low cost.\cite{CompressedDrori2021} Continuous innovation, from new imaging and processing techniques to portable hardware and sophisticated software, ensures its central role in fields including oncology, cardiology, brain imaging, obstretics\cite{DualNyayapathi2024}, emergency medicine and many more. As technology advances, the demand for higher resolution and more sophisticated imaging modes constantly pushes system designers to capture more data with an ever-increasing number of channels and higher sampling rates. The management of these massive datastreams strains the limits of acquisition, real-time processing and transmission in ultrasound-based imaging modalities. Addressing this data-rate bottle neck is therefore a critical step in enabling future innovations.

Data-rate reduction, respectively data compression in general can be approached from a variety of different angles. We can broadly categorise them in two classes: \textbf{Lossy} and \textbf{lossless} compression.

Prior work on lossy methods has shown that very high compression ratios can be achieved by transforming the ultrasound signal into another domain and intelligently discarding information that is deemed less important, respectively considered to be noise. For instance, Drori et al.\cite{CompressDrori2021} have proposed a novel beamforming algorithm in the frequency domain that is equivalent to time domain DAS. This, combined with compressed sensing techniques and sub-Nyquist sampling allows them to filter and massively compress the ultrasound data by exploiting the finite rate of innovation (FRI) structure of the beamformed data.

Similar techniques based on the Discrete Wavelet Transform (DWT) can efficiently denoise and significantly reduce the dimensionality of medical imaging data by thresholding small wavelet coefficients. In the landscape of lossy compression algorithms, the DWT shows distinguished potential due to the following characteristics: It contains information about the signal in time and frequency domain simultaneously and it is able to solve the three problems noisiness, excessive storage space and low information content.\cite{RNS-BasedNagornov2022} These properties make it a promising paradigm for further work on resource constrained systems.

% intro to listentolight

However, the ListenToLight research platform, which this thesis is based on, has very high bandwidth capabilities and computational power. Hence, this system is not required to achieve compression ratios that are as high as possible, it should rather provide the highest quality data possible. This requirement rules out the data reduction techniques mentioned above, as they are inherently lossy. Furthermore, since ListenToLight is a research platform, the type of reconstruction should not be restricted as for example in the frequency domain beamforming approach mentioned earlier.

The main goal of this thesis is to present a lossless data-rate reduction algorithm such that 

% put QASA as future work in section 6

% main goal of this thesis.



%s that of the data-rate bottleneck in US imaging. The formation of a US image requires large amounts of data due mostly to two factors: High sampling rates, multiples or even magnitudes of order beyond the Nyquist rate to ensure high resolution beamforming, and a large number of data channels (and corresponding receivers), typically tens to hundreds, to enable high spatial resolution. These high data rates constrain advanced processing algorithms and portable hardware